{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4743673-9124-4273-ad3a-1280c01af09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at IDEA-CCNL/Erlangshen-TCBert-330M-Sentence-Embedding-Chinese were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt-based Sentence Similarity\n",
    "# To extract sentence representations.\n",
    "from transformers import BertForMaskedLM, BertTokenizer\n",
    "import torch\n",
    "\n",
    "# Loading models\n",
    "tokenizer=BertTokenizer.from_pretrained(\"IDEA-CCNL/Erlangshen-TCBert-330M-Sentence-Embedding-Chinese\")\n",
    "model=BertForMaskedLM.from_pretrained(\"IDEA-CCNL/Erlangshen-TCBert-330M-Sentence-Embedding-Chinese\")\n",
    "\n",
    "# Cosine similarity function\n",
    "cos = torch.nn.CosineSimilarity(dim=0, eps=1e-8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86aae2d1-a4bc-42f7-a260-d3ad62f29a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.2260)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "\n",
    "    # To extract sentence representations for training data\n",
    "    training_input = tokenizer(\"怎样的房子才算户型方正？\", return_tensors=\"pt\")\n",
    "    training_output = model(**training_input, output_hidden_states=True)\n",
    "    training_representation = torch.mean(training_output.hidden_states[-1].squeeze(), dim=0)\n",
    "\n",
    "    # To extract sentence representations for training data\n",
    "    test_input = tokenizer(\"下面是一则关于[MASK][MASK]的新闻：股票放量下趺，大资金出逃谁在接盘？\", return_tensors=\"pt\")\n",
    "    test_output = model(**test_input, output_hidden_states=True)\n",
    "    test_representation = torch.mean(test_output.hidden_states[-1].squeeze(), dim=0)\n",
    "\n",
    "print(torch.mean(test_output.hidden_states[-1].squeeze(), dim=0).shape)\n",
    "# Calculate similarity scores\n",
    "similarity_score = cos(training_representation, test_representation)\n",
    "similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bb5216a-a816-435e-a967-736183aa9fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.5.1-cp310-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: filelock in /Users/untergang/miniconda3/envs/AI_Medical/lib/python3.10/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/untergang/miniconda3/envs/AI_Medical/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in /Users/untergang/miniconda3/envs/AI_Medical/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/untergang/miniconda3/envs/AI_Medical/lib/python3.10/site-packages (from torch) (2024.10.0)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/untergang/miniconda3/envs/AI_Medical/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/untergang/miniconda3/envs/AI_Medical/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Using cached torch-2.5.1-cp310-none-macosx_11_0_arm64.whl (63.9 MB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Installing collected packages: sympy, networkx, torch\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.3\n",
      "    Uninstalling sympy-1.13.3:\n",
      "      Successfully uninstalled sympy-1.13.3\n",
      "Successfully installed networkx-3.4.2 sympy-1.13.1 torch-2.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381d7169-4d97-4a9e-a4a7-3258c1c65687",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_Medical",
   "language": "python",
   "name": "ai_medical"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
